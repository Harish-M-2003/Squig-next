"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[26],{4958:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>r,metadata:()=>d,toc:()=>c});var s=o(1527),i=o(8672);const r={sidebar_label:"Token",sidebar_position:2},t="Token",d={id:"developer-docs/token",title:"Token",description:"The Token module in Squig defines the Token class, which represents individual tokens used during lexical analysis. These tokens are generated by the Lexer module and are the smallest units of syntax in a Squig program.",source:"@site/docs/developer-docs/token.md",sourceDirName:"developer-docs",slug:"/developer-docs/token",permalink:"/developer-docs/token",draft:!1,unlisted:!1,editUrl:"https://github.com/Harish-M-2003/Squig-Docusaurus/tree/main/docs/developer-docs/token.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_label:"Token",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Project Structure",permalink:"/developer-docs/project-structure"},next:{title:"Lexer",permalink:"/developer-docs/lexer"}},l={},c=[{value:"Token Class",id:"token-class",level:2},{value:"Attributes:",id:"attributes",level:3},{value:"Example Usage:",id:"example-usage",level:3},{value:"List of Tokens:",id:"list-of-tokens",level:2},{value:"Code Explanation",id:"code-explanation",level:2},{value:"Example Usage:",id:"example-usage-1",level:3},{value:"Conclusion",id:"conclusion",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"token",children:"Token"}),"\n",(0,s.jsx)(n.p,{children:"The Token module in Squig defines the Token class, which represents individual tokens used during lexical analysis. These tokens are generated by the Lexer module and are the smallest units of syntax in a Squig program."}),"\n",(0,s.jsx)(n.h2,{id:"token-class",children:"Token Class"}),"\n",(0,s.jsx)(n.p,{children:"The Token class encapsulates the properties of a token, including its type, value, and position in the source code."}),"\n",(0,s.jsx)(n.h3,{id:"attributes",children:"Attributes:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type"}),": The type of the token, indicating its classification (e.g., keyword, operator, identifier)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Value"}),": The value associated with the token, representing its content or meaning (e.g., the actual keyword or identifier)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Position"}),": The position of the token in the source code, denoted by line and column numbers."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-usage",children:"Example Usage:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from Token import Token\r\n\r\n# Create a token for the keyword \'if\'\r\ntoken = Token(token_type="keyword", token_value="if", token_position=(1, 1))\r\n\r\nprint(token)\r\n# Output: keyword : if\n'})}),"\n",(0,s.jsx)(n.h2,{id:"list-of-tokens",children:"List of Tokens:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Keywords"}),": ",(0,s.jsx)(n.code,{children:"if"}),", ",(0,s.jsx)(n.code,{children:"else"}),", ",(0,s.jsx)(n.code,{children:"elif"}),", ",(0,s.jsx)(n.code,{children:"function"}),", ",(0,s.jsx)(n.code,{children:"for"}),", ",(0,s.jsx)(n.code,{children:"return"}),", ",(0,s.jsx)(n.code,{children:"break"}),", ",(0,s.jsx)(n.code,{children:"continue"}),", ",(0,s.jsx)(n.code,{children:"let"}),", ",(0,s.jsx)(n.code,{children:"delete"}),", ",(0,s.jsx)(n.code,{children:"type"}),", ",(0,s.jsx)(n.code,{children:"use"}),", ",(0,s.jsx)(n.code,{children:"log"}),", ",(0,s.jsx)(n.code,{children:"file"}),", ",(0,s.jsx)(n.code,{children:"close"}),", ",(0,s.jsx)(n.code,{children:"default"}),", ",(0,s.jsx)(n.code,{children:"case"}),", ",(0,s.jsx)(n.code,{children:"switch"}),", ",(0,s.jsx)(n.code,{children:"true"}),", ",(0,s.jsx)(n.code,{children:"false"}),", ",(0,s.jsx)(n.code,{children:"pop"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Operators"}),": ",(0,s.jsx)(n.code,{children:"plus"}),", ",(0,s.jsx)(n.code,{children:"minus"}),", ",(0,s.jsx)(n.code,{children:"divide"}),", ",(0,s.jsx)(n.code,{children:"dot"}),", ",(0,s.jsx)(n.code,{children:"modulo"}),", ",(0,s.jsx)(n.code,{children:"mul"}),", ",(0,s.jsx)(n.code,{children:"gt"}),", ",(0,s.jsx)(n.code,{children:"lt"}),", ",(0,s.jsx)(n.code,{children:"gte"}),", ",(0,s.jsx)(n.code,{children:"lte"}),", ",(0,s.jsx)(n.code,{children:"ne"}),", ",(0,s.jsx)(n.code,{children:"colon"}),", ",(0,s.jsx)(n.code,{children:"comma"}),", ",(0,s.jsx)(n.code,{children:"lparen"}),", ",(0,s.jsx)(n.code,{children:"rparen"}),", ",(0,s.jsx)(n.code,{children:"not"}),", ",(0,s.jsx)(n.code,{children:"power"}),", ",(0,s.jsx)(n.code,{children:"eql"}),", ",(0,s.jsx)(n.code,{children:"lbrace"}),", ",(0,s.jsx)(n.code,{children:"rbrace"}),", ",(0,s.jsx)(n.code,{children:"lsquare"}),", ",(0,s.jsx)(n.code,{children:"rsquare"}),", ",(0,s.jsx)(n.code,{children:"colonPlus"}),", ",(0,s.jsx)(n.code,{children:"colonMinus"}),", ",(0,s.jsx)(n.code,{children:"colonDivide"}),", ",(0,s.jsx)(n.code,{children:"colonMul"}),", ",(0,s.jsx)(n.code,{children:"colonPower"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Literals"}),": ",(0,s.jsx)(n.code,{children:"string"}),", ",(0,s.jsx)(n.code,{children:"int"}),", ",(0,s.jsx)(n.code,{children:"float"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Special Tokens"}),": ",(0,s.jsx)(n.code,{children:"newline"}),", ",(0,s.jsx)(n.code,{children:"eof"}),", ",(0,s.jsx)(n.code,{children:"writetofile"}),", ",(0,s.jsx)(n.code,{children:"mutstring"}),", ",(0,s.jsx)(n.code,{children:"input"}),", ",(0,s.jsx)(n.code,{children:"and"}),", ",(0,s.jsx)(n.code,{children:"or"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"code-explanation",children:"Code Explanation"}),"\n",(0,s.jsx)(n.p,{children:"The provided code defines the Token class and initializes tokens for various types of language elements such as keywords, operators, literals, and special tokens. Here's a breakdown of the code:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Token Class"}),": Defines a class named Token with attributes for type, value, and position."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Initialization"}),": Initializes a Token object with the specified type, value, and position."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Representation"}),": Provides a string representation of the Token object, including its type and value."]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"example-usage-1",children:"Example Usage:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from Token import Token\r\n\r\n# Create a token for the keyword \'if\'\r\ntoken = Token(token_type="keyword", token_value="if", token_position=(1, 1))\r\n\r\nprint(token)\r\n# Output: keyword : if\n'})}),"\n",(0,s.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,s.jsx)(n.p,{children:"The Token module in Squig provides a flexible mechanism for representing tokens, enabling accurate lexical analysis of Squig source code. By classifying tokens into distinct types and associating them with relevant values and positions, Squig facilitates subsequent phases of the compilation process, ensuring correct interpretation and execution of Squig programs."})]})}function h(e={}){const{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(a,{...e})}):a(e)}},8672:(e,n,o)=>{o.d(n,{Z:()=>d,a:()=>t});var s=o(959);const i={},r=s.createContext(i);function t(e){const n=s.useContext(r);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);